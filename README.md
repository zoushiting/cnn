1.网络结构参数对模型精度的影响
2.通过手动调参提升模型性能的方法
3.CNN 相比 MLP 在图像分类任务中的优势

4.在代码顶部 CONFIG 中选择模型：
"model": "mlp"   # 或 "cnn"


5.BP 神经网络（MLP）：通过调参，使 测试集准确率达到 98% 及以上

6.卷积神经网络（CNN）：通过调参，使 测试集准确率达到 99% 及以上

7.训练参数调整（可选）
可在 CONFIG 中修改：
学习率 lr
训练轮数 epochs
批大小 batch_size

8.作业提交内容（必须上传）

请提交以下内容：

（1）实验代码
修改后的 cnn.py

（2）结果截图或图片
MLP 达到 ≥98% 准确率的运行结果截图
CNN 达到 ≥99% 准确率的运行结果截图

（3）对应的训练曲线图（results.png，可多张）

（4）实验说明
简要说明所采用的网络结构和最终准确率
可写在 README.md 末尾或单独提交文档

9.最终提交PR时，请将标题修改为：学号+姓名，1979801234张三

实验说明：
1. MLP（多层感知机）
输入层：MNIST图像经Flatten处理为784维向量（28×28像素）；
隐藏层：3层全连接隐藏层，结构为「784 → 1024 → 512 → 256」，激活函数采用ReLU，各隐藏层后添加Dropout（ dropout rate=0.2 ）防止过拟合；
输出层：10维向量（对应0-9共10个数字类别），采用全连接层实现。
2. CNN（卷积神经网络）
卷积层：3层卷积层，通道数依次为「1→32→64→128」，卷积核尺寸均为3×3， Padding=1 ，激活函数采用ReLU；
池化层：每个卷积层后跟随1层2×2 MaxPooling，实现特征降维与平移不变性；
全连接层：经Flatten处理后接入2层全连接层，结构为「128×3×3 → 256 → 10」，卷积层与全连接层后分别添加Dropout（ dropout rate=0.25 ）防止过拟合。
